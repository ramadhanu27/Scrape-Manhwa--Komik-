# ğŸ¨ Manhwa Scraper - Shinigami Edition

Web scraper untuk mengekstrak data manhwa dari website **Shinigami (07.shinigami.asia)** dan menyimpannya dalam format JSON.

## ğŸŒŸ 3 Metode Scraping

### 1. âœ… **HTML Manual** (RECOMMENDED)
File: `shinigami-scraper-html.js`
- âœ… Ringan & cepat
- âœ… Tidak perlu install Chrome
- âœ… Copy HTML dari browser â†’ Parse â†’ JSON
- ğŸ“– Baca: `README-SOLUSI.md`

### 2. ğŸ¤– **Puppeteer** (Otomatis)
File: `shinigami-scraper-puppeteer.js`
- âœ… Otomatis scraping
- âœ… Support pagination
- âŒ Perlu install Chrome (~300MB)
- ğŸ“– Baca: `README-PUPPETEER.md`

### 3. ğŸ“¦ **Axios + Cheerio** (Untuk website static)
File: `scraper.js`
- âœ… Ringan & cepat
- âŒ Tidak bisa scrape Shinigami (JS rendering)
- âœ… Cocok untuk website static
- ğŸ“– Baca: `README-SHINIGAMI.md`

## ğŸ“‹ Fitur

- âœ… Scrape daftar manhwa (title, rating, views, bookmarks, status)
- âœ… Scrape detail manhwa (author, genres, chapters, description)
- âœ… Scrape URL gambar dari chapter
- âœ… Export ke JSON dengan struktur rapi
- âœ… Generate summary dan statistik
- âœ… Filter data (by rating, status, views)
- âœ… Support pagination

## ğŸš€ Instalasi

### 1. Pastikan Node.js Terinstall

Cek versi Node.js:
```bash
node --version
```

Jika belum terinstall, download dari: https://nodejs.org/

### 2. Install Dependencies

```bash
npm install
```

Atau install manual:
```bash
npm install axios cheerio fs-extra
```

## ğŸš€ Quick Start (RECOMMENDED)

### Metode HTML Manual - Paling Mudah!

```bash
# Jalankan scraper dengan sample data
node shinigami-scraper-html.js
```

**Hasil**: File JSON tersimpan di folder `data/`

### Untuk Data Lengkap:

1. **Buka browser** â†’ https://07.shinigami.asia/search
2. **Tekan F12** â†’ Tab Elements
3. **Cari element** `<div class="grid mb-24 lg:grid-cols-2 grid-cols-1 gap-24">`
4. **Klik kanan** â†’ Copy â†’ Copy outerHTML
5. **Buka file** `shinigami-scraper-html.js`
6. **Paste HTML** ke variable `sampleHTML`
7. **Jalankan**: `node shinigami-scraper-html.js`

âœ… **Selesai!** Data tersimpan di `data/manhwa-from-html.json`

## ğŸ“– Cara Penggunaan Lanjutan

### A. Scraper HTML (Manual)

```javascript
import ShinigamiScraperHTML from './shinigami-scraper-html.js';

const scraper = new ShinigamiScraperHTML();

// Scrape dari HTML string
const html = `<div class="grid">...</div>`;
const manhwaList = await scraper.scrapeFromHTML(html);

// Atau dari file
const manhwaList = await scraper.scrapeFromFile('page.html');

// Simpan ke JSON
await scraper.saveToJSON(manhwaList, 'result.json');
```

### B. Scraper Puppeteer (Otomatis)

**Install Chrome dulu:**
```bash
npx puppeteer browsers install chrome
```

**Jalankan:**
```javascript
import ShinigamiScraperPuppeteer from './shinigami-scraper-puppeteer.js';

const scraper = new ShinigamiScraperPuppeteer();
await scraper.init();

const manhwaList = await scraper.scrapeManhwaList('https://07.shinigami.asia/search');
await scraper.saveToJSON(manhwaList, 'result.json');

await scraper.close();
```

### C. Scraper Generic (Website Static)

Edit file `scraper.js` dan ganti URL:

```javascript
const baseUrl = 'https://your-manhwa-site.com';
const manhwaUrl = 'https://your-manhwa-site.com/manga/solo-leveling';
const manhwaTitle = 'Solo Leveling';
```

### Langkah 2: Sesuaikan CSS Selector

Setiap website memiliki struktur HTML berbeda. Anda perlu menyesuaikan CSS selector di dua fungsi utama:

**A. Fungsi `getChapterList()` - untuk mengambil daftar chapter:**
```javascript
$('.chapter-list a, .chapter-item a, .wp-manga-chapter a').each((i, elem) => {
  // Sesuaikan selector dengan website target
});
```

**B. Fungsi `getChapterImages()` - untuk mengambil gambar:**
```javascript
$('.reading-content img, .chapter-content img, #readerarea img').each((i, elem) => {
  // Sesuaikan selector dengan website target
});
```

### Langkah 3: Test Scraper

Jalankan test untuk memastikan selector bekerja:

```bash
npm test
```

Atau:
```bash
node test-scraper.js
```

### Langkah 4: Jalankan Scraper

Uncomment kode di fungsi `main()` dalam `scraper.js`, lalu jalankan:

```bash
npm start
```

Atau:
```bash
node scraper.js
```

## ğŸ’» Contoh Kode

### Download Chapter 1-5

```javascript
import ManhwaScraper from './scraper.js';

const scraper = new ManhwaScraper('https://manhwa-site.com');
await scraper.downloadManhwa(
  'https://manhwa-site.com/manga/solo-leveling',
  'Solo Leveling',
  1,  // chapter awal
  5   // chapter akhir
);
```

### Download Semua Chapter

```javascript
await scraper.downloadManhwa(
  'https://manhwa-site.com/manga/solo-leveling',
  'Solo Leveling'
);
```

### Ambil Info Manhwa

```javascript
const info = await scraper.getManhwaInfo(manhwaUrl);
console.log(info.title);
console.log(info.author);
console.log(info.genres);
```

### Ambil Daftar Chapter

```javascript
const chapters = await scraper.getChapterList(manhwaUrl);
console.log(`Total chapter: ${chapters.length}`);
```

## ğŸ“ Struktur Folder

```
scraper web/
â”œâ”€â”€ downloads/              # Folder hasil download
â”‚   â””â”€â”€ Solo Leveling/      # Folder per manhwa
â”‚       â”œâ”€â”€ Chapter 1/      # Folder per chapter
â”‚       â”‚   â”œâ”€â”€ page_001.jpg
â”‚       â”‚   â”œâ”€â”€ page_002.jpg
â”‚       â”‚   â””â”€â”€ ...
â”‚       â””â”€â”€ Chapter 2/
â”‚           â””â”€â”€ ...
â”œâ”€â”€ scraper.js              # File utama scraper
â”œâ”€â”€ test-scraper.js         # File untuk testing
â”œâ”€â”€ package.json            # Dependencies
â””â”€â”€ README.md               # Dokumentasi
```

## ğŸ”§ Troubleshooting

### 1. Tidak Ada Chapter/Gambar Ditemukan

**Penyebab:** CSS selector tidak sesuai dengan struktur HTML website.

**Solusi:**
- Buka website target di browser
- Klik kanan â†’ Inspect Element
- Lihat struktur HTML untuk daftar chapter dan gambar
- Sesuaikan selector di `getChapterList()` dan `getChapterImages()`

### 2. Error 403 Forbidden

**Penyebab:** Website memblokir request dari bot.

**Solusi:**
- Ubah User-Agent di `this.headers`
- Tambahkan delay lebih lama antar request
- Gunakan proxy jika diperlukan

### 3. Gambar Tidak Bisa Didownload

**Penyebab:** Website menggunakan lazy loading atau proteksi gambar.

**Solusi:**
- Periksa atribut gambar: `data-src`, `data-lazy-src`, dll
- Tambahkan atribut tersebut di fungsi `getChapterImages()`

### 4. Error ECONNRESET / Timeout

**Penyebab:** Koneksi terputus atau website lambat.

**Solusi:**
- Tingkatkan timeout di axios config
- Tambahkan retry logic
- Periksa koneksi internet

## âš ï¸ Disclaimer

- Gunakan scraper ini dengan bijak dan hormati Terms of Service website target
- Jangan overload server dengan terlalu banyak request
- Beberapa website melarang scraping - periksa robots.txt
- Untuk penggunaan pribadi saja, jangan untuk komersial
- Hormati hak cipta konten

## ğŸ“š Dependencies

- **axios** (^1.6.0) - HTTP client untuk request
- **cheerio** (^1.0.0-rc.12) - jQuery-like HTML parser
- **fs-extra** (^11.1.1) - File system operations

## ğŸ› ï¸ Customisasi Lanjutan

### Menambah Delay

Edit fungsi `delay()` atau ubah nilai delay:

```javascript
await this.delay(3000); // 3 detik
```

### Mengubah User-Agent

Edit di constructor:

```javascript
this.headers = {
  'User-Agent': 'Your Custom User Agent'
};
```

### Menambah Referer

Beberapa website memerlukan referer:

```javascript
this.headers = {
  ...this.headers,
  'Referer': 'https://specific-page.com'
};
```

### Download dengan Proxy

Tambahkan proxy config di axios:

```javascript
const response = await axios.get(url, {
  headers: this.headers,
  proxy: {
    host: 'proxy-server.com',
    port: 8080
  }
});
```

## ğŸ“ License

MIT License - Bebas digunakan dan dimodifikasi.

## ğŸ¤ Kontribusi

Silakan fork dan submit pull request untuk improvement!

---

**Happy Scraping! ğŸ‰**
